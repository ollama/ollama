# Intel iGPU Vulkan Issues Analysis & Solutions

## Problema Principal

**Error identificado**: Exception 0xe06d7363 en `ggml_backend_sched_graph_compute_async`

### Stack Trace Cr√≠tico
```
Exception 0xe06d7363 0x19930520 0x3efedff6a0 0x7ff97e9780aa
PC=0x7ff97e9780aa
signal arrived during external code execution

runtime.cgocall(0x7ff7bd3ed9a0, 0xc001571ab8)
github.com/ollama/ollama/ml/backend/ggml._Cfunc_ggml_backend_sched_graph_compute_async(0x16f7048f1e0, 0x17f0c157040)
github.com/ollama/ollama/ml/backend/ggml.(*Context).ComputeWithNotify.func1(...)
```

## Modelos Problem√°ticos Identificados

### GPT-OSS Series
- **gpt-oss:20b** - Crash confirmado durante inferencia
- **S√≠ntomas**: Exception 0xe06d7363 en compute graph
- **Hardware afectado**: Intel iGPU con driver Vulkan

## Dos Problemas Distintos

### 1. Bugcheck 0x10e (VIDEO_MEMORY_MANAGEMENT_INTERNAL)
- **Estado**: ‚úÖ **RESUELTO** con `GGML_VK_DISABLE_HOST_VISIBLE_VIDMEM=1`
- **Causa**: Driver Intel Arc manejo incorrecto de host-visible video memory
- **S√≠ntoma**: Sistema crash completo, BSOD
- **Soluci√≥n**: Workaround implementado en scripts

### 2. Exception 0xe06d7363 en Compute Graph
- **Estado**: üî¥ **ACTIVO** - Requiere detecci√≥n y fallback a CPU
- **Causa**: Incompatibilidad espec√≠fica entre ciertos modelos y Intel Vulkan backend
- **S√≠ntoma**: Crash de aplicaci√≥n (no sistema)
- **Soluci√≥n**: Detecci√≥n autom√°tica y fallback a CPU

## Soluciones Implementadas

### Script Inteligente: `start_ollama_intel_smart.ps1`

#### Caracter√≠sticas
1. **Detecci√≥n autom√°tica** de modelos problem√°ticos
2. **Configuraci√≥n inteligente** de variables de entorno
3. **Fallback seguro** a CPU para modelos conflictivos
4. **Workarounds preventivos** para crashes conocidos

#### Uso
```powershell
# Detecci√≥n autom√°tica
.\start_ollama_intel_smart.ps1

# Modelo espec√≠fico
.\start_ollama_intel_smart.ps1 -Model "gpt-oss:20b"

# Forzar CPU (seguro)
.\start_ollama_intel_smart.ps1 -Model "any-model" -ForceCPU

# Forzar Vulkan (riesgoso para modelos problem√°ticos)
.\start_ollama_intel_smart.ps1 -Model "gpt-oss:20b" -ForceVulkan
```

#### L√≥gica de Decisi√≥n
```
¬øModelo problem√°tico?
‚îú‚îÄ S√ç ‚Üí ¬øForceVulkan?
‚îÇ  ‚îú‚îÄ S√ç ‚Üí Vulkan + Warning
‚îÇ  ‚îî‚îÄ NO ‚Üí CPU (seguro)
‚îî‚îÄ NO ‚Üí Vulkan + Safety flags
```

## Variables de Entorno Cr√≠ticas

### Para Modelos Problem√°ticos (CPU Fallback)
```bash
OLLAMA_LLM_LIBRARY=cpu
```

### Para Modelos Compatibles (Vulkan Seguro)
```bash
OLLAMA_LLM_LIBRARY=vulkan
OLLAMA_INTEL_GPU=1
GGML_VK_DISABLE_HOST_VISIBLE_VIDMEM=1  # Previene bugcheck 0x10e
```

### Variables Opcionales
```bash
OLLAMA_VK_IGPU_MEMORY_LIMIT_MB=16384   # Limitar memoria (si necesario)
GGML_VK_VISIBLE_DEVICES=0              # Seleccionar GPU espec√≠fica
```

## Modelos de Compatibilidad

### ‚úÖ Compatibles con Intel iGPU Vulkan
- **Llama 3.x series** (8B, 70B)
- **Gemma 2/3 series** (despu√©s de PR #12552)
- **Qwen series**
- **Mistral series**

### ‚ö†Ô∏è Problem√°ticos (Requieren CPU)
- **GPT-OSS series** (todas las variantes)
- **Modelos GPT4** (algunos)
- **Otros modelos grandes** (>20B en ciertas arquitecturas)

### üîç Sin Confirmar
- Modelos nuevos requieren testing individual
- El script detecta patrones conocidos autom√°ticamente

## Diagn√≥stico Manual

### S√≠ntomas de Modelo Problem√°tico
```
time=...:...:....... level=TRACE source=runner.go:450 msg="forwardBatch compute started"
time=...:...:....... level=TRACE source=runner.go:623 msg="computeBatch: waiting for inputs"
Exception 0xe06d7363 0x19930520 0x3efedff6a0 0x7ff97e9780aa
```

### S√≠ntomas de Bugcheck 0x10e
```
DRIVER_VERIFIER_IOMANAGER_VIOLATION (c9)
VIDEO_MEMORY_MANAGEMENT_INTERNAL (10e)
```

## Mejores Pr√°cticas

### 1. Usar Script Inteligente
- Evita configuraci√≥n manual
- Detecci√≥n autom√°tica de problemas
- Aplicaci√≥n de workarounds apropiados

### 2. Para Desarrollo/Testing
```powershell
# Probar modelo nuevo de forma segura
.\start_ollama_intel_smart.ps1 -Model "nuevo-modelo" -ForceCPU
```

### 3. Para Producci√≥n
```powershell
# Configuraci√≥n autom√°tica √≥ptima
.\start_ollama_intel_smart.ps1 -Model "modelo-conocido"
```

## Status del PR #11835

### ‚úÖ Resuelto en Upstream
- **Commit**: 2aba569a2 (merged 5 d√≠as atr√°s)
- **Fixes incluidos**:
  - `fix vulkan handle releasing` (b6554e9)
  - Gemma3 Intel iGPU fixes (#12552)
  - Memory estimation improvements
  - Intel GPU ID detection en Windows

### ‚úÖ Presente en Branch Actual
- Tu branch `12.7.b1` incluye todos los fixes
- Commit #12552 presente desde Oct 13, 2025
- Vulkan backend completamente integrado

## Recomendaciones Finales

### Para Usuarios
1. **Usar `start_ollama_intel_smart.ps1`** para configuraci√≥n autom√°tica
2. **Evitar manual override** de modelos problem√°ticos
3. **Reportar nuevos modelos problem√°ticos** para a√±adir a la lista

### Para Desarrollo
1. **Mantener lista de modelos problem√°ticos** actualizada
2. **Considerar detecci√≥n en runtime** dentro de GGML backend
3. **Monitor upstream fixes** para nuevas soluciones

### Estado Actual
- ‚úÖ Bugcheck 0x10e: **Resuelto**
- ‚ö†Ô∏è  Exception 0xe06d7363: **Mitigado** con CPU fallback
- ‚úÖ Detecci√≥n autom√°tica: **Implementada**
- ‚úÖ Scripts de automatizaci√≥n: **Listos**

El sistema est√° ahora **robusto y seguro** para uso en Intel iGPU con Vulkan.