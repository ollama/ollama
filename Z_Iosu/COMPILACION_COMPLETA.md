# GU√çA COMPLETA: Compilaci√≥n Ollama 0.12.6.99 con Interfaz Gr√°fica Funcional

## üöÄ CONFIGURACI√ìN PREVIA: ccache (RECOMENDADO)

### ‚ö° ¬øC√≥mo funciona el cache en Ollama?

| Componente | Sistema de Cache | Beneficio |
|------------|------------------|-----------|
| **Bibliotecas C/C++** (DLLs) | **ccache** | 50-80% m√°s r√°pido en recompilaciones |
| **CLI Go** (ollama.exe) | **Go build cache** | Autom√°tico, muy eficiente |
| **App Bandeja** (MSVC) | **Go build cache** | Autom√°tico |

### üìã Configuraci√≥n ccache (Solo para bibliotecas C/C++)

**Ejecuta ANTES de compilar (solo una vez):**

```powershell
# Verificar que ccache est√° instalado
ccache --version
# Debe mostrar: ccache version 4.12.1

# Configurar ccache para m√°ximo rendimiento
ccache --set-config compression=true
ccache --set-config compression_level=1
ccache --set-config max_size=10G
ccache --set-config sloppiness=time_macros

# Limpiar estad√≠sticas para seguimiento limpio
ccache -z

# Verificar configuraci√≥n
ccache --show-config | Select-String "compression|max_size|sloppiness"
```

### ‚úÖ Resultado esperado:
```
(config) compression = true
(config) compression_level = 1  
(config) max_size = 10.0 GB
(config) sloppiness = time_macros
```

### üìä Monitoreo durante compilaci√≥n:
```powershell
# Ver cache de ccache (bibliotecas C/C++)
ccache -s

# Ver cache de Go (ollama.exe + app)
go env GOCACHE
```

### üéØ **Velocidades esperadas:**
- **Primera compilaci√≥n**: ~10 minutos (llena ambos caches)
- **Recompilaciones completas**: ~3-5 minutos  
- **Solo Go (buildOllama)**: ~30 segundos (Go cache muy eficiente)

**NOTA:** ccache solo acelera las bibliotecas C/C++ (buildCPU, buildCUDA13). Go tiene su propio sistema de cache autom√°tico.

---

## ‚úÖ SOLUCI√ìN FINAL - COPY & PASTE

### üéØ COMANDO √öNICO AUTOM√ÅTICO (RECOMENDADO) ‚≠ê

**Copia y pega esto en PowerShell desde `C:\IA\tools\ollama`:**

```powershell
$env:VERSION = "0.12.6.99"
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildCPU buildCUDA13 buildVulkan gatherDependencies buildOllama buildApp buildInstaller
```
$env:VERSION = "0.12.6.99"; powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\smart_build.ps1 -Verbose

$env:VERSION = "0.12.6.99"; powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\smart_build.ps1 -Verbose
**Eso es TODO.** Espera ~10 minutos y tendr√°s `dist\OllamaSetup.exe` completo y funcional.

---
 powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\start_ollama_vulkan_intel.ps1 *> C:\IA\tools\ollama\logs\ollama.log    
 
### Compilaci√≥n Paso a Paso (Si prefieres ver el progreso)

```powershell
# ============================================================================
# PASO 0: Instalar Vulkan SDK (solo una vez, requiere administrador)
# ============================================================================
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\install-vulkan-sdk.ps1

# ============================================================================
# PASO 1: Bibliotecas CPU, CUDA y Vulkan con MSVC
# ============================================================================
$env:VERSION = "0.12.6.99"
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildCPU buildCUDA13 buildVulkan gatherDependencies

# ============================================================================
# PASO 2: CLI (ollama.exe) con llvm-mingw
# ============================================================================
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildOllama

# ============================================================================
# PASO 3: App de Bandeja con MSVC (autom√°tico desde script arreglado)
# ============================================================================
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildApp

# ============================================================================
# PASO 4: Generar Instalador
# ============================================================================
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildInstaller
```

**NOTA:** El script `build_windows.ps1` ahora autom√°ticamente limpia el entorno de llvm-mingw antes de compilar la app, garantizando que use MSVC puro para evitar el bug del men√∫ contextual.

---

## üì¶ Archivos Generados

```
dist\
‚îú‚îÄ‚îÄ OllamaSetup.exe (450 MB)           ‚Üê Instalador completo
‚îú‚îÄ‚îÄ windows-amd64-app.exe (6.81 MB)    ‚Üê App bandeja (MSVC)
‚îú‚îÄ‚îÄ windows-amd64\
‚îÇ   ‚îú‚îÄ‚îÄ ollama.exe (34.88 MB)          ‚Üê CLI (llvm-mingw)
‚îÇ   ‚îî‚îÄ‚îÄ lib\ollama\
‚îÇ       ‚îú‚îÄ‚îÄ ggml-*.dll (8 archivos)    ‚Üê CPU backends
‚îÇ       ‚îú‚îÄ‚îÄ cuda_v13\*.dll (3 archivos) ‚Üê CUDA 13
‚îÇ       ‚îú‚îÄ‚îÄ ggml-vulkan.dll (~50 MB)   ‚Üê Vulkan backend (AMD/Intel/NVIDIA)
‚îÇ       ‚îî‚îÄ‚îÄ *.dll (17 archivos)        ‚Üê Runtime MSVC
```

**Total: 29 DLLs + 2 ejecutables + instalador (con soporte Vulkan universal)**

---

## üöÄ Instalaci√≥n

```powershell
# 1. Detener procesos antiguos
Get-Process | Where-Object { $_.Name -like "*ollama*" } | Stop-Process -Force

# 2. Desinstalar versi√≥n anterior (si existe)
if (Test-Path "$env:LOCALAPPDATA\Programs\Ollama\unins000.exe") {
    Start-Process "$env:LOCALAPPDATA\Programs\Ollama\unins000.exe" -ArgumentList "/SILENT" -Wait
}

# 3. Instalar nueva versi√≥n
.\dist\OllamaSetup.exe

# 4. Verificar
ollama --version
# Output: ollama version is 0.12.6.99
```

---

## ‚úÖ Verificaci√≥n de la App de Bandeja

1. **Busca el icono ü¶ô** en la bandeja del sistema (abajo a la derecha del reloj)
2. **Haz clic DERECHO** en el icono
3. **Debe aparecer el men√∫:**
   - Open Ollama
   - Update Available (si hay updates)
   - Quit Ollama

Si NO aparece el men√∫ ‚Üí La app se compil√≥ con llvm-mingw (bug conocido)  
Si S√ç aparece el men√∫ ‚Üí ‚úÖ Compilaci√≥n correcta con MSVC

---

## ‚ö†Ô∏è PROBLEMA CR√çTICO: App de Bandeja con llvm-mingw

### S√≠ntoma
- ‚úÖ El proceso `ollama app.exe` se ejecuta
- ‚úÖ El icono ü¶ô aparece en la bandeja
- ‚ùå **Clic derecho NO muestra men√∫**
- ‚ùå No se puede abrir la interfaz gr√°fica

### Causa Ra√≠z
**llvm-mingw** tiene incompatibilidad con Win32 API para men√∫s contextuales (system tray menus).

### Soluci√≥n
**Compilar `buildApp` con MSVC puro (sin llvm-mingw):**

| Componente | Compilador | Raz√≥n |
|------------|-----------|-------|
| `ollama.exe` (CLI) | llvm-mingw | CGO + stdlib.h compatibility |
| `ollama app.exe` (GUI) | MSVC | Win32 API (men√∫s contextuales) |
| Bibliotecas DLL | MSVC | Compatibilidad con CUDA/CPU |

---

## üîß PROBLEMA SOLUCIONADO: Aplicaci√≥n de Windows no arranca (DLLs faltantes)

### ‚ùå S√≠ntoma Original
Antes solo copiabas `ollama.exe` y funcionaba, pero ahora:
- ‚úÖ El ejecutable `ollama.exe` existe y funciona en directorio de compilaci√≥n
- ‚ùå Al copiar solo `ollama.exe` a tu aplicaci√≥n de Windows: **servidor no arranca**
- ‚ùå Logs del servidor est√°n "a cero" (vac√≠os)
- ‚ùå El proceso se cierra inmediatamente sin generar logs

### üîç Causa Ra√≠z
**Las versiones anteriores** de Ollama ten√≠an bibliotecas compiladas **est√°ticamente** (incluidas dentro del .exe).

**Ollama 0.12.6.99 con CUDA** usa bibliotecas **din√°micas** (.dll) separadas que deben estar presentes en runtime.

### ‚úÖ Soluci√≥n DEFINITIVA

**ANTES** (incorrecto - solo ejecutable):
```
App_Windows/
‚îî‚îÄ‚îÄ ollama.exe ‚Üê Solo esto NO funciona
```

**AHORA** (correcto - estructura completa):
```
App_Windows/
‚îú‚îÄ‚îÄ ollama.exe                    ‚Üê Ejecutable principal
‚îî‚îÄ‚îÄ lib/
    ‚îî‚îÄ‚îÄ ollama/
        ‚îú‚îÄ‚îÄ ggml-cuda.dll         ‚Üê Backend CUDA (293 MB)
        ‚îú‚îÄ‚îÄ ggml-base.dll         ‚Üê Backend base
        ‚îú‚îÄ‚îÄ ggml-cpu-*.dll        ‚Üê Backends CPU optimizados (8 archivos)
        ‚îú‚îÄ‚îÄ cublas64_13.dll       ‚Üê Bibliotecas CUDA cuBLAS
        ‚îú‚îÄ‚îÄ cublasLt64_13.dll     ‚Üê Bibliotecas CUDA cuBLASLt  
        ‚îú‚îÄ‚îÄ msvcp140*.dll         ‚Üê Runtime Visual C++ (5 archivos)
        ‚îú‚îÄ‚îÄ vcruntime140*.dll     ‚Üê Runtime Visual C++ (2 archivos)
        ‚îî‚îÄ‚îÄ api-ms-win-*.dll      ‚Üê APIs Windows Runtime (10 archivos)
```

### üìã Pasos de Migraci√≥n para tu Aplicaci√≥n de Windows

1. **Detener servidor existente** (si est√° corriendo):
   ```powershell
   taskkill /F /IM ollama.exe
   ```

2. **Eliminar archivo √∫nico anterior**:
   ```powershell
   del "C:\tu_app\ollama.exe"
   ```

3. **Copiar TODA la estructura** desde compilaci√≥n:
   ```powershell
   # Origen (compilaci√≥n exitosa)
   $origen = "C:\IA\tools\ollama\dist\windows-amd64"
   
   # Destino (tu aplicaci√≥n de Windows)  
   $destino = "C:\tu_app"
   
   # Copiar estructura completa
   robocopy "$origen" "$destino" /E /R:3 /W:1
   ```

4. **Verificar estructura** (script de diagn√≥stico):
   ```powershell
   # Copiar script de diagn√≥stico
   copy "C:\IA\tools\ollama\dist\windows-amd64\diagnose_ollama_fixed.ps1" "C:\tu_app\"
   
   # Ejecutar desde tu aplicaci√≥n
   cd "C:\tu_app"
   .\diagnose_ollama_fixed.ps1
   ```

5. **Resultado esperado**:
   ```
   ‚úÖ ollama.exe encontrado (31.18 MB)
   ‚úÖ 28 bibliotecas encontradas  
   ‚úÖ Servidor inicia correctamente
   ‚úÖ API responde correctamente
   ```

### üéØ Por qu√© es CR√çTICO mantener la estructura

| Componente | Ubicaci√≥n Requerida | Raz√≥n |
|------------|-------------------|-------|
| `ollama.exe` | Ra√≠z aplicaci√≥n | Ejecutable principal |
| `lib\ollama\*.dll` | **Relativo al .exe** | ollama.exe busca DLLs en esta ruta espec√≠fica |
| `OLLAMA_LIBRARY_PATH` | Variable entorno | Override manual (opcional) |

**NOTA:** El ejecutable `ollama.exe` busca autom√°ticamente las bibliotecas en `lib\ollama\` **relativo a su ubicaci√≥n**. Si cambias esta estructura, el servidor no arrancar√°.

### üìä Verificaci√≥n Post-Migraci√≥n

**Script de verificaci√≥n autom√°tica**:
```powershell
# Verificar que tu aplicaci√≥n de Windows funciona
cd "C:\tu_app"

# 1. Verificar archivos cr√≠ticos
$criticos = @("ollama.exe", "lib\ollama\ggml-cuda.dll", "lib\ollama\ggml-base.dll")
foreach ($file in $criticos) {
    if (Test-Path $file) { Write-Host "‚úÖ $file" } 
    else { Write-Host "‚ùå $file FALTANTE" }
}

# 2. Configurar entorno (por si acaso)
$env:OLLAMA_LIBRARY_PATH = (Get-Location).Path + "\lib\ollama"

# 3. Probar versi√≥n
.\ollama.exe --version

# 4. Probar servidor (2 segundos de prueba)
$proceso = Start-Process -FilePath "ollama.exe" -ArgumentList "serve" -PassThru -NoNewWindow
Start-Sleep 2
if (-not $proceso.HasExited) {
    Write-Host "‚úÖ Servidor funciona correctamente"
    Stop-Process -Id $proceso.Id -Force
} else {
    Write-Host "‚ùå Servidor fall√≥ - revisar logs"
}
```

---

## üîß Troubleshooting

### 1. "Build Failed" pero ollama.exe existe
**S√≠ntoma:** Script muestra "Build Failed" pero ollama.exe se genera correctamente.
```powershell
# Verificar si realmente fall√≥
if (Test-Path "ollama.exe") { 
    Write-Host "‚úÖ Compilaci√≥n exitosa: $([math]::Round((Get-Item ollama.exe).Length/1MB, 2)) MB" 
} else { 
    Write-Host "‚ùå Compilaci√≥n fall√≥ realmente" 
}
```
**Causa:** Advertencias de C++ (codecvt_utf8) que Go interpreta como error.  
**Soluci√≥n:** Script actualizado ignora warnings y verifica archivo generado.

### 2. buildOllama falla con mezcla de entornos
**S√≠ntoma:** Error de VS2022 + llvm-mingw incompatible.
```powershell
# Ejecutar manualmente (siempre funciona)
$env:VERSION = "0.12.6.99"; $env:CGO_ENABLED="1"
$llvmPath = (Resolve-Path "C:\llvm-mingw-ucrt\llvm-mingw-*").Path
$env:PATH = "$llvmPath\bin;$env:PATH"
$env:CC = "$llvmPath\bin\gcc.exe"; $env:CXX = "$llvmPath\bin\g++.exe"
go build -v -a -trimpath -ldflags "-s -w -X=github.com/ollama/ollama/version.Version=$env:VERSION -X=github.com/ollama/ollama/server.mode=release" .
```

### 3. App no aparece en bandeja
```powershell
# Verificar proceso
Get-Process | Where-Object { $_.Name -like "*ollama*" }

# Debe mostrar:
# - ollama app (app de bandeja)  
# - ollama (servidor backend)
```

### 4. Men√∫ contextual no funciona
```powershell
# Verificar que la app se compil√≥ con MSVC (no llvm-mingw)
# Recompilar siguiendo PASO 3 arriba
```

### 5. ccache no se usa
**Normal:** ccache solo funciona en bibliotecas C/C++ (buildCPU, buildCUDA13).  
Go tiene su propio cache autom√°tico muy eficiente.
```powershell
# Ver estad√≠sticas de ambos sistemas
ccache -s              # Cache C/C++
go env GOCACHE         # Cache Go
```

### 6. Verificar DLLs instaladas
```powershell
Get-ChildItem "$env:LOCALAPPDATA\Programs\Ollama\lib\ollama" -Recurse -Filter "*.dll" | Measure-Object
# Debe mostrar: Count = 28
```

---

## üìù Resumen de Requisitos

### Software Necesario
- ‚úÖ Visual Studio 2022 Professional
- ‚úÖ CUDA 13.0
- ‚úÖ llvm-mingw-20240619-ucrt-x86_64
- ‚úÖ Go 1.24+
- ‚úÖ Inno Setup 6.5.1
- ‚úÖ windres (de llvm-mingw)

### Variables de Entorno
```powershell
$env:VERSION = "0.12.6.99"
$env:CUDA_PATH_V13_0 = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
```

---

## üéØ Comandos R√°pidos

### Compilaci√≥n Completa Autom√°tica (Un Solo Comando)
```powershell
$env:VERSION = "0.12.6.99"
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildCPU buildCUDA13 gatherDependencies buildOllama buildApp buildInstaller
```

### Solo Recompilar y Reinstalar
```powershell
# Si ya tienes las DLLs compiladas y solo cambi√≥ el c√≥digo
powershell -ExecutionPolicy Bypass -File Z_Iosu\scripts\build_windows.ps1 buildOllama buildApp buildInstaller
```

### Compilar ollama.exe Manualmente (Siempre funciona)
```powershell
# Comando manual que NUNCA falla
$env:VERSION = "0.12.6.99"; $env:CGO_ENABLED="1"
$llvmPath = (Resolve-Path "C:\llvm-mingw-ucrt\llvm-mingw-*").Path; $env:PATH = "$llvmPath\bin;$env:PATH"
$env:CC = "$llvmPath\bin\gcc.exe"; $env:CXX = "$llvmPath\bin\g++.exe"
go build -v -a -trimpath -ldflags "-s -w -X=github.com/ollama/ollama/version.Version=$env:VERSION -X=github.com/ollama/ollama/server.mode=release" .

# Copiar a dist (si usas comando manual)
cp .\ollama.exe .\dist\windows-amd64\
```

### Reinstalaci√≥n Limpia
```powershell
Get-Process | Where-Object { $_.Name -like "*ollama*" } | Stop-Process -Force
Start-Process "$env:LOCALAPPDATA\Programs\Ollama\unins000.exe" -ArgumentList "/SILENT" -Wait
.\dist\OllamaSetup.exe
```

---

## ‚úÖ Resultado Final

- **Versi√≥n:** Ollama 0.12.6.99 (test-llamacpp-bump)
- **Soporte:** Granite + Docling (llama.cpp 1deee0f8)
- **Backend:** CUDA 13.0 + Vulkan 1.4.321.1 (soporte universal GPU)
- **Interfaz:** App de bandeja 100% funcional con men√∫ contextual
- **CLI:** Compatible con llvm-mingw UCRT

**¬°Disfruta tu comida!** üçΩÔ∏è
