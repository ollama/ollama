From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: jmorganca <jmorganca@gmail.com>
Date: Sat, 21 Feb 2026 16:55:05 -0800
Subject: [PATCH] ggml-metal: guard mul_mat_id map0 and add ne20=22
 specialization

---
 ggml/src/ggml-metal/ggml-metal-ops.cpp | 144 +++++++++++++++----------
 ggml/src/ggml-metal/ggml-metal.metal   |   1 +
 2 files changed, 87 insertions(+), 58 deletions(-)

diff --git a/ggml/src/ggml-metal/ggml-metal-ops.cpp b/ggml/src/ggml-metal/ggml-metal-ops.cpp
index 4ac135603..b7f49ed82 100644
--- a/ggml/src/ggml-metal/ggml-metal-ops.cpp
+++ b/ggml/src/ggml-metal/ggml-metal-ops.cpp
@@ -25,6 +25,22 @@ static ggml_metal_buffer_id ggml_metal_get_buffer_id(const ggml_tensor * t) {
     return ggml_metal_buffer_get_id(ctx, t);
 }
 
+static bool ggml_metal_mul_mm_id_map0_has_specialization(const int ne20) {
+    switch (ne20) {
+        case 1:
+        case 2:
+        case 4:
+        case 6:
+        case 8:
+        case 10:
+        case 16:
+        case 22:
+            return true;
+        default:
+            return false;
+    }
+}
+
 struct ggml_metal_op {
     ggml_metal_op(
         ggml_metal_device_t dev,
@@ -1961,7 +1977,13 @@ int ggml_metal_op_mul_mat_id(ggml_metal_op_t ctx, int idx) {
     // ne21 = n_rows (batch size)
     const int ne21_mm_id_min = 32;
 
-    if (props_dev->has_simdgroup_mm && ne00 >= 64 && (ne21 >= ne21_mm_id_min)) {
+    bool use_mul_mm_id =
+        props_dev->has_simdgroup_mm &&
+        ne00 >= 64 &&
+        (ne21 >= ne21_mm_id_min) &&
+        ggml_metal_mul_mm_id_map0_has_specialization(ne20);
+
+    if (use_mul_mm_id) {
         // some Metal matrix data types require aligned pointers
         // ref: https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf (Table 2.5)
         //switch (op->src[0]->type) {
@@ -1978,77 +2000,83 @@ int ggml_metal_op_mul_mat_id(ggml_metal_op_t ctx, int idx) {
         ggml_metal_buffer_id bid_ids = bid_tpe;
         bid_ids.offs += ggml_metal_op_mul_mat_id_extra_tpe(op);
 
-        {
-            ggml_metal_kargs_mul_mm_id_map0 args = {
-                ne02,
-                ne10,
-                ne11, // n_expert_used (bcast)
-                nb11,
-                nb12,
-                ne21, // n_tokens
-                ne20, // n_expert_used
-                nb21,
-            };
+        auto pipeline_map0 = ggml_metal_library_get_pipeline_mul_mm_id_map0(lib, ne02, ne20);
+        auto pipeline_mm_id = ggml_metal_library_get_pipeline_mul_mm_id(lib, op);
 
-            auto pipeline = ggml_metal_library_get_pipeline_mul_mm_id_map0(lib, ne02, ne20);
+        if (!pipeline_map0.pipeline || !pipeline_mm_id.pipeline) {
+            GGML_LOG_WARN("%s: falling back to mul_mv_id: missing mul_mm_id pipeline for ne20=%d ne02=%d\n", __func__, ne20, ne02);
+            use_mul_mm_id = false;
+        } else {
+            {
+                ggml_metal_kargs_mul_mm_id_map0 args = {
+                    ne02,
+                    ne10,
+                    ne11, // n_expert_used (bcast)
+                    nb11,
+                    nb12,
+                    ne21, // n_tokens
+                    ne20, // n_expert_used
+                    nb21,
+                };
 
-            const size_t smem = pipeline.smem;
+                const size_t smem = pipeline_map0.smem;
 
-            GGML_ASSERT(ne02 <= ggml_metal_pipeline_max_theads_per_threadgroup(pipeline));
+                GGML_ASSERT(ne02 <= ggml_metal_pipeline_max_theads_per_threadgroup(pipeline_map0));
 
-            GGML_ASSERT(smem <= props_dev->max_theadgroup_memory_size);
+                GGML_ASSERT(smem <= props_dev->max_theadgroup_memory_size);
 
-            ggml_metal_encoder_set_pipeline(enc, pipeline);
-            ggml_metal_encoder_set_bytes   (enc, &args, sizeof(args), 0);
-            ggml_metal_encoder_set_buffer  (enc, bid_src2, 1);
-            ggml_metal_encoder_set_buffer  (enc, bid_tpe,  2);
-            ggml_metal_encoder_set_buffer  (enc, bid_ids,  3);
+                ggml_metal_encoder_set_pipeline(enc, pipeline_map0);
+                ggml_metal_encoder_set_bytes   (enc, &args, sizeof(args), 0);
+                ggml_metal_encoder_set_buffer  (enc, bid_src2, 1);
+                ggml_metal_encoder_set_buffer  (enc, bid_tpe,  2);
+                ggml_metal_encoder_set_buffer  (enc, bid_ids,  3);
 
-            ggml_metal_encoder_set_threadgroup_memory_size(enc, smem, 0);
+                ggml_metal_encoder_set_threadgroup_memory_size(enc, smem, 0);
 
-            ggml_metal_encoder_dispatch_threadgroups(enc, 1, 1, 1, ne02, 1, 1);
-        }
+                ggml_metal_encoder_dispatch_threadgroups(enc, 1, 1, 1, ne02, 1, 1);
+            }
 
-        // this barrier is always needed because the next kernel has to wait for the id maps to be computed
-        ggml_metal_op_concurrency_reset(ctx);
+            // this barrier is always needed because the next kernel has to wait for the id maps to be computed
+            ggml_metal_op_concurrency_reset(ctx);
 
-        {
-            auto pipeline = ggml_metal_library_get_pipeline_mul_mm_id(lib, op);
-
-            ggml_metal_kargs_mul_mm_id args = {
-                /*.ne00  =*/ ne00,
-                /*.ne02  =*/ ne02,
-                /*.nb01  =*/ nb01,
-                /*.nb02  =*/ nb02,
-                /*.nb03  =*/ nb03,
-                /*.ne11  =*/ ne11, // n_expert_used (bcast)
-                /*.nb10  =*/ nb10,
-                /*.nb11  =*/ nb11,
-                /*.nb12  =*/ nb12,
-                /*.nb13  =*/ nb13,
-                /*.ne20  =*/ ne20, // n_expert_used
-                /*.ne21  =*/ ne21, // n_tokens
-                /*.ne0   =*/ ne0,
-                /*.ne1   =*/ ne1,
-                /*.r2    =*/ r2,
-                /*.r3    =*/ r3,
-            };
+            {
+                ggml_metal_kargs_mul_mm_id args = {
+                    /*.ne00  =*/ ne00,
+                    /*.ne02  =*/ ne02,
+                    /*.nb01  =*/ nb01,
+                    /*.nb02  =*/ nb02,
+                    /*.nb03  =*/ nb03,
+                    /*.ne11  =*/ ne11, // n_expert_used (bcast)
+                    /*.nb10  =*/ nb10,
+                    /*.nb11  =*/ nb11,
+                    /*.nb12  =*/ nb12,
+                    /*.nb13  =*/ nb13,
+                    /*.ne20  =*/ ne20, // n_expert_used
+                    /*.ne21  =*/ ne21, // n_tokens
+                    /*.ne0   =*/ ne0,
+                    /*.ne1   =*/ ne1,
+                    /*.r2    =*/ r2,
+                    /*.r3    =*/ r3,
+                };
 
-            ggml_metal_encoder_set_pipeline(enc, pipeline);
-            ggml_metal_encoder_set_bytes   (enc, &args, sizeof(args), 0);
-            ggml_metal_encoder_set_buffer  (enc, bid_src0, 1);
-            ggml_metal_encoder_set_buffer  (enc, bid_src1, 2);
-            ggml_metal_encoder_set_buffer  (enc, bid_tpe,  3);
-            ggml_metal_encoder_set_buffer  (enc, bid_ids,  4);
-            ggml_metal_encoder_set_buffer  (enc, bid_dst,  5);
+                ggml_metal_encoder_set_pipeline(enc, pipeline_mm_id);
+                ggml_metal_encoder_set_bytes   (enc, &args, sizeof(args), 0);
+                ggml_metal_encoder_set_buffer  (enc, bid_src0, 1);
+                ggml_metal_encoder_set_buffer  (enc, bid_src1, 2);
+                ggml_metal_encoder_set_buffer  (enc, bid_tpe,  3);
+                ggml_metal_encoder_set_buffer  (enc, bid_ids,  4);
+                ggml_metal_encoder_set_buffer  (enc, bid_dst,  5);
 
-            const size_t smem = pipeline.smem;
+                const size_t smem = pipeline_mm_id.smem;
 
-            ggml_metal_encoder_set_threadgroup_memory_size(enc, smem, 0);
+                ggml_metal_encoder_set_threadgroup_memory_size(enc, smem, 0);
 
-            ggml_metal_encoder_dispatch_threadgroups(enc, (ne21 + 31)/32, (ne01 + 63)/64, ne02, 128, 1, 1);
+                ggml_metal_encoder_dispatch_threadgroups(enc, (ne21 + 31)/32, (ne01 + 63)/64, ne02, 128, 1, 1);
+            }
         }
-    } else {
+    }
+
+    if (!use_mul_mm_id) {
         auto pipeline = ggml_metal_library_get_pipeline_mul_mv_id(lib, op);
 
         const int nr0 = pipeline.nr0;
diff --git a/ggml/src/ggml-metal/ggml-metal.metal b/ggml/src/ggml-metal/ggml-metal.metal
index c37447a10..4f338aa13 100644
--- a/ggml/src/ggml-metal/ggml-metal.metal
+++ b/ggml/src/ggml-metal/ggml-metal.metal
@@ -9427,6 +9427,7 @@ template [[host_name("kernel_mul_mm_id_map0_ne20_6" )]] kernel kernel_mul_mm_id_
 template [[host_name("kernel_mul_mm_id_map0_ne20_8" )]] kernel kernel_mul_mm_id_map0_t kernel_mul_mm_id_map0<8>;
 template [[host_name("kernel_mul_mm_id_map0_ne20_10")]] kernel kernel_mul_mm_id_map0_t kernel_mul_mm_id_map0<10>;
 template [[host_name("kernel_mul_mm_id_map0_ne20_16")]] kernel kernel_mul_mm_id_map0_t kernel_mul_mm_id_map0<16>;
+template [[host_name("kernel_mul_mm_id_map0_ne20_22")]] kernel kernel_mul_mm_id_map0_t kernel_mul_mm_id_map0<22>;
 
 template<typename S0, typename S0_4x4, typename S0_8x8, typename S1, typename S1_2x4, typename S1_8x8, typename block_q, short nl, void (*dequantize_func)(device const block_q *, short, thread S0_4x4 &), typename T0, typename T0_4x4, typename T1, typename T1_2x4>
 kernel void kernel_mul_mm_id(
