name: Build Ollama with CUDA 12 and Vulkan Support

on:
  schedule:
    - cron: '0 22 * * *'  # 每天 UTC 22:00 (北京时间早上 6:00)
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  OLLAMA_REPO: ollama/ollama

jobs:
  check-updates:
    runs-on: ubuntu-latest
    outputs:
      should_build: ${{ steps.check.outputs.should_build }}
      commit_sha: ${{ steps.check.outputs.commit_sha }}
    steps:
      - name: Check for updates
        id: check
        run: |
          # 获取 ollama 主分支最新 commit
          LATEST_SHA=$(curl -s https://api.github.com/repos/${{ env.OLLAMA_REPO }}/commits/main | jq -r '.sha')
          echo "Latest commit: $LATEST_SHA"
          
          # 检查是否已经构建过这个版本
          IMAGE_EXISTS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            "https://ghcr.io/v2/${{ github.repository_owner }}/ollama/manifests/$LATEST_SHA" \
            -o /dev/null -w "%{http_code}")
          
          if [ "$IMAGE_EXISTS" = "200" ]; then
            echo "Image already exists for commit $LATEST_SHA"
            echo "should_build=false" >> $GITHUB_OUTPUT
          else
            echo "New commit found, will build"
            echo "should_build=true" >> $GITHUB_OUTPUT
            echo "commit_sha=$LATEST_SHA" >> $GITHUB_OUTPUT
          fi

  build-and-push:
    needs: check-updates
    if: needs.check-updates.outputs.should_build == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Maximize Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          df -h

      - name: Checkout Ollama Source
        uses: actions/checkout@v4
        with:
          repository: ${{ env.OLLAMA_REPO }}
          ref: main
          fetch-depth: 1

      - name: Generate Dockerfile
        run: |
          cat > Dockerfile << 'DOCKERFILE'
          FROM nvidia/cuda:12.6.3-devel-ubuntu22.04 AS builder
          
          ARG GO_VERSION=1.23.4
          ARG CMAKE_VERSION=3.28.3
          ARG VULKAN_SDK_VERSION=1.4.321.1
          
          ENV DEBIAN_FRONTEND=noninteractive
          ENV PATH=/usr/local/go/bin:$PATH
          
          WORKDIR /build
          
          # 安装基础依赖
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                ca-certificates \
                curl \
                git \
                build-essential \
                wget \
                libvulkan-dev \
                vulkan-tools \
                libvulkan1 \
                pkg-config && \
              rm -rf /var/lib/apt/lists/*
          
          # 安装 CMake
          RUN curl -L "https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-x86_64.tar.gz" | \
              tar -xz -C /usr/local --strip-components=1
          
          # 安装 Go
          RUN curl -L "https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz" | \
              tar -xz -C /usr/local
          
          # 复制源代码
          COPY . .
          
          # 编译 Vulkan 后端
          RUN cmake --preset 'Vulkan' && \
              cmake --build --parallel --preset 'Vulkan' && \
              cmake --install build --component Vulkan --strip
          
          # 编译 CUDA 12 后端
          RUN cmake --preset 'CUDA 12' && \
              cmake --build --parallel --preset 'CUDA 12' && \
              cmake --install build --component CUDA --strip
          
          # 编译 Ollama 主程序
          RUN go generate ./... && \
              go build -trimpath -ldflags "-s -w" -o /build/bin/ollama .
          
          # 最终镜像
          FROM ubuntu:22.04
          
          ENV DEBIAN_FRONTEND=noninteractive
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                ca-certificates \
                libvulkan1 \
                vulkan-tools && \
              rm -rf /var/lib/apt/lists/*
          
          # 复制编译好的文件
          COPY --from=builder /build/bin/ollama /bin/ollama
          COPY --from=builder /build/dist/lib/ollama /lib/ollama
          
          # 设置环境变量
          ENV OLLAMA_HOST=0.0.0.0:11434
          ENV LD_LIBRARY_PATH=/lib/ollama
          ENV OLLAMA_VULKAN=1
          
          EXPOSE 11434
          
          ENTRYPOINT ["/bin/ollama"]
          CMD ["serve"]
          DOCKERFILE

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Lowercase Username
        run: |
          echo "OWNER_LC=${GITHUB_REPOSITORY_OWNER,,}" >> ${GITHUB_ENV}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama
          tags: |
            type=raw,value=latest
            type=raw,value=${{ needs.check-updates.outputs.commit_sha || github.sha }}
            type=raw,value={{date 'YYYYMMDD'}}

      - name: Build and Push Docker Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          platforms: linux/amd64
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Create Release Summary
        run: |
          echo "## Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ needs.check-updates.outputs.commit_sha || github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tags:** " >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.meta.outputs.tags }}" | sed 's/^/  - /' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 使用方法" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# 使用 CUDA" >> $GITHUB_STEP_SUMMARY
          echo "docker run -d --gpus all -v ollama:/root/.ollama -p 11434:11434 ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# 使用 Vulkan (AMD 核显)" >> $GITHUB_STEP_SUMMARY
          echo "docker run -d --device=/dev/dri -v ollama:/root/.ollama -p 11434:11434 -e OLLAMA_VULKAN=1 ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
