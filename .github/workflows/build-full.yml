name: Build Ollama with CUDA and Vulkan Support

on:
  schedule:
    - cron: '0 22 * * *'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  OLLAMA_REPO: ollama/ollama

jobs:
  check-updates:
    runs-on: ubuntu-latest
    outputs:
      should_build: ${{ steps.check.outputs.should_build }}
      commit_sha: ${{ steps.check.outputs.commit_sha }}
    steps:
      - name: Check for updates
        id: check
        run: |
          LATEST_SHA=$(curl -s https://api.github.com/repos/${{ env.OLLAMA_REPO }}/commits/main | jq -r '.sha')
          echo "Latest commit: $LATEST_SHA"
          
          IMAGE_EXISTS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            "https://ghcr.io/v2/${{ github.repository_owner }}/ollama/manifests/$LATEST_SHA" \
            -o /dev/null -w "%{http_code}")
          
          if [ "$IMAGE_EXISTS" = "200" ]; then
            echo "Image already exists for commit $LATEST_SHA"
            echo "should_build=false" >> $GITHUB_OUTPUT
          else
            echo "New commit found, will build"
            echo "should_build=true" >> $GITHUB_OUTPUT
            echo "commit_sha=$LATEST_SHA" >> $GITHUB_OUTPUT
          fi

  build-and-push:
    needs: check-updates
    if: needs.check-updates.outputs.should_build == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Maximize Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          df -h

      - name: Checkout Ollama Source
        uses: actions/checkout@v4
        with:
          repository: ${{ env.OLLAMA_REPO }}
          ref: main
          fetch-depth: 1

      - name: Generate Dockerfile
        run: |
          cat > Dockerfile << 'DOCKERFILE'
          ARG GOLANG_VERSION=1.23.4
          ARG CMAKE_VERSION=3.28.3
          # ä½¿ç”¨ CUDA 13 ä»¥æ”¯æŒæœ€æ–°çš„ GPU æž¶æž„
          ARG CUDA_VERSION_MAJOR=13
          ARG CUDA_VERSION=13.0.1
          ARG VULKAN_SDK_VERSION=1.4.321.1
          
          # ==================== CPU åº“æž„å»ºé˜¶æ®µ ====================
          FROM ubuntu:24.04 AS cpu-builder
          ARG CMAKE_VERSION
          
          ENV DEBIAN_FRONTEND=noninteractive
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                git \
                build-essential \
                curl \
                ccache \
                ca-certificates && \
              rm -rf /var/lib/apt/lists/*
          
          RUN curl -fsSL "https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-x86_64.tar.gz" | \
              tar xz -C /usr/local --strip-components=1
          
          WORKDIR /build
          COPY CMakeLists.txt CMakePresets.json ./
          COPY ml/backend/ggml/ggml ml/backend/ggml/ggml
          
          RUN --mount=type=cache,target=/root/.ccache \
              cmake --preset CPU && \
              cmake --build --parallel --preset CPU && \
              cmake --install build --component CPU --strip
          
          # ==================== Vulkan åº“æž„å»ºé˜¶æ®µ ====================
          FROM ubuntu:24.04 AS vulkan-builder
          ARG CMAKE_VERSION
          ARG VULKAN_SDK_VERSION
          
          ENV DEBIAN_FRONTEND=noninteractive
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                git \
                build-essential \
                curl \
                ccache \
                ca-certificates \
                wget \
                gnupg \
                software-properties-common && \
              wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | tee /etc/apt/trusted.gpg.d/lunarg.asc && \
              wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list https://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list && \
              apt-get update && \
              apt-get install -y --no-install-recommends vulkan-sdk && \
              rm -rf /var/lib/apt/lists/*
          
          RUN curl -fsSL "https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-x86_64.tar.gz" | \
              tar xz -C /usr/local --strip-components=1
          
          WORKDIR /build
          COPY CMakeLists.txt CMakePresets.json ./
          COPY ml/backend/ggml/ggml ml/backend/ggml/ggml
          
          RUN --mount=type=cache,target=/root/.ccache \
              cmake --preset Vulkan -DOLLAMA_RUNNER_DIR="vulkan" && \
              cmake --build --parallel --preset Vulkan && \
              cmake --install build --component Vulkan --strip
          
          # ==================== CUDA 13 åº“æž„å»ºé˜¶æ®µ ====================
          FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu24.04 AS cuda-builder
          ARG CMAKE_VERSION
          ARG CUDA_VERSION_MAJOR
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                git \
                build-essential \
                curl \
                ccache \
                ca-certificates && \
              rm -rf /var/lib/apt/lists/*
          
          RUN curl -fsSL "https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-x86_64.tar.gz" | \
              tar xz -C /usr/local --strip-components=1
          
          WORKDIR /build
          COPY CMakeLists.txt CMakePresets.json ./
          COPY ml/backend/ggml/ggml ml/backend/ggml/ggml
          
          # ä½¿ç”¨ CUDA 13 preset
          RUN --mount=type=cache,target=/root/.ccache \
              cmake --preset "CUDA ${CUDA_VERSION_MAJOR}" -DOLLAMA_RUNNER_DIR="cuda_v${CUDA_VERSION_MAJOR}" && \
              cmake --build --parallel --preset "CUDA ${CUDA_VERSION_MAJOR}" && \
              cmake --install build --component CUDA --strip
          
          # ==================== Go äºŒè¿›åˆ¶æž„å»ºé˜¶æ®µ ====================
          FROM ubuntu:24.04 AS go-builder
          ARG GOLANG_VERSION
          ARG CMAKE_VERSION
          
          ENV DEBIAN_FRONTEND=noninteractive
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                git \
                build-essential \
                curl \
                ca-certificates \
                rsync && \
              rm -rf /var/lib/apt/lists/*
          
          RUN git config --global user.email "builder@ollama.local" && \
              git config --global user.name "Ollama Builder"
          
          RUN curl -fsSL "https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-x86_64.tar.gz" | \
              tar xz -C /usr/local --strip-components=1
          
          RUN curl -fsSL "https://go.dev/dl/go${GOLANG_VERSION}.linux-amd64.tar.gz" | \
              tar xz -C /usr/local
          
          ENV PATH=/usr/local/go/bin:$PATH
          ENV GOPATH=/go
          ENV CGO_ENABLED=1
          
          WORKDIR /build
          COPY . .
          
          RUN make -f Makefile.sync clean sync
          RUN go mod download
          RUN go generate ./... && \
              go build -trimpath -ldflags="-s -w" -o /bin/ollama .
          
          # ==================== æœ€ç»ˆè¿è¡Œé•œåƒ ====================
          FROM ubuntu:24.04
          
          ENV DEBIAN_FRONTEND=noninteractive
          
          RUN apt-get update && \
              apt-get install -y --no-install-recommends \
                ca-certificates \
                wget \
                gnupg && \
              wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | tee /etc/apt/trusted.gpg.d/lunarg.asc && \
              wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list https://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list && \
              apt-get update && \
              apt-get install -y --no-install-recommends \
                libvulkan1 \
                vulkan-tools && \
              apt-get clean && \
              rm -rf /var/lib/apt/lists/*
          
          COPY --from=go-builder /bin/ollama /usr/bin/ollama
          COPY --from=cpu-builder /build/dist/lib/ollama /usr/lib/ollama
          COPY --from=vulkan-builder /build/dist/lib/ollama /usr/lib/ollama
          COPY --from=cuda-builder /build/dist/lib/ollama /usr/lib/ollama
          
          ENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
          ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/ollama
          ENV NVIDIA_VISIBLE_DEVICES=all
          ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
          ENV OLLAMA_HOST=0.0.0.0:11434
          
          EXPOSE 11434
          
          ENTRYPOINT ["/usr/bin/ollama"]
          CMD ["serve"]
          DOCKERFILE

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Lowercase Username
        run: |
          echo "OWNER_LC=${GITHUB_REPOSITORY_OWNER,,}" >> ${GITHUB_ENV}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama
          tags: |
            type=raw,value=latest
            type=raw,value=${{ needs.check-updates.outputs.commit_sha || github.sha }}
            type=raw,value={{date 'YYYYMMDD'}}

      - name: Build and Push Docker Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          platforms: linux/amd64
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            GOLANG_VERSION=1.23.4
            CMAKE_VERSION=3.28.3
            CUDA_VERSION_MAJOR=13
            CUDA_VERSION=13.0.1

      - name: Create Release Summary
        run: |
          echo "## ðŸŽ‰ æž„å»ºæˆåŠŸ" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ é•œåƒä¿¡æ¯" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** \`${{ needs.check-updates.outputs.commit_sha || github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **æž„å»ºæ—¶é—´:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **æ”¯æŒ:** CUDA 13.0, Vulkan, CPU" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ·ï¸ é•œåƒæ ‡ç­¾" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.meta.outputs.tags }}" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ ä½¿ç”¨æ–¹æ³•" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### 1. æ‹‰å–é•œåƒ" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### 2. ä½¿ç”¨ NVIDIA GPU (CUDA 13)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d --gpus all \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### 3. ä½¿ç”¨ AMD æ ¸æ˜¾ (Vulkan)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d \\" >> $GITHUB_STEP_SUMMARY
          echo "  --device=/dev/dri \\" >> $GITHUB_STEP_SUMMARY
          echo "  --device=/dev/kfd \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  -e OLLAMA_VULKAN=1 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### 4. ä½¿ç”¨ Intel æ ¸æ˜¾ (Vulkan)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d \\" >> $GITHUB_STEP_SUMMARY
          echo "  --device=/dev/dri \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  -e OLLAMA_VULKAN=1 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”§ éªŒè¯å’Œæµ‹è¯•" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "# è¿›å…¥å®¹å™¨" >> $GITHUB_STEP_SUMMARY
          echo "docker exec -it ollama bash" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# æŸ¥çœ‹å·²å®‰è£…çš„åº“" >> $GITHUB_STEP_SUMMARY
          echo "ls -la /usr/lib/ollama/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# æŸ¥çœ‹ Vulkan è®¾å¤‡" >> $GITHUB_STEP_SUMMARY
          echo "vulkaninfo --summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# æµ‹è¯•å°æ¨¡åž‹" >> $GITHUB_STEP_SUMMARY
          echo "ollama run llama3.2:1b" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“ é‡è¦æç¤º" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **CUDA 13**: æ”¯æŒæœ€æ–°çš„ NVIDIA GPU (åŒ…æ‹¬ RTX 40 ç³»åˆ—)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Vulkan**: æ”¯æŒ AMD å’Œ Intel æ ¸æ˜¾/ç‹¬æ˜¾" >> $GITHUB_STEP_SUMMARY
          echo "- âš ï¸ Vulkan éœ€è¦è®¾ç½® \`OLLAMA_VULKAN=1\` çŽ¯å¢ƒå˜é‡" >> $GITHUB_STEP_SUMMARY
          echo "- âš ï¸ AMD éœ€è¦: \`--device=/dev/kfd --device=/dev/dri\`" >> $GITHUB_STEP_SUMMARY
          echo "- âš ï¸ Intel éœ€è¦: \`--device=/dev/dri\`" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ’¡ é€‰æ‹©ç‰¹å®š GPU: è®¾ç½® \`GGML_VK_VISIBLE_DEVICES=0\`" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ’¡ æŸ¥çœ‹æ—¥å¿—: \`docker logs -f ollama\`" >> $GITHUB_STEP_SUMMARY
