name: Build Ollama (Switch Base Image - Final)

on:
  schedule:
    - cron: '0 22 * * *'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  USERNAME: ${{ github.actor }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      # 1. 清理磁盘
      - name: Free Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force

      # 2. 拉取官方代码
      - name: Checkout Official Upstream
        uses: actions/checkout@v4
        with:
          repository: ollama/ollama
          ref: main

      # 3. 【终极修复】更换基础镜像 + 重写依赖
      - name: Patch Dockerfile (Replace Base Image)
        shell: python
        run: |
          import re
          
          print(">>> 开始读取 Dockerfile...")
          with open("Dockerfile", "r") as f:
              content = f.read()
          
          # === 修复 1: 替换坏掉的基础镜像 ===
          # 原本的 rocm/dev-almalinux-8 镜像源已坏，换成官方纯净的 almalinux:8
          # 这样我们就能获得一个干净、网络正常的 RHEL 8 环境
          print(">>> 正在替换基础镜像为 almalinux:8 ...")
          content = re.sub(
              r"FROM --platform=linux/amd64 rocm/dev-almalinux-8.*? AS base-amd64",
              "FROM --platform=linux/amd64 almalinux:8 AS base-amd64",
              content
          )
          
          # === 修复 2: 重写依赖安装命令 ===
          # 因为换了纯净镜像，我们需要手动安装 gcc-10 和工具
          # 还要添加 NVIDIA 源 (为了后面的 CUDA)
          print(">>> 正在注入新的构建依赖命令...")
          new_run_cmd = """RUN dnf install -y 'dnf-command(config-manager)' \\
              && dnf config-manager --set-enabled appstream \\
              && dnf install -y gcc-toolset-10 git make wget tar xz \\
              && dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo \\
              && dnf clean all"""
          
          # 替换那个巨长的、报错的 RUN yum install ... 命令
          content = re.sub(
              r"RUN yum install.*?cuda-rhel8\.repo", 
              new_run_cmd, 
              content, 
              flags=re.DOTALL
          )

          # === 修复 3: 切断 ROCm 依赖 ===
          # 因为我们换了纯净 base，没有预装 ROCm 工具，所以必须强制切断 ROCm 构建
          # 否则 rocm 阶段会报错。反正你也不用 AMD 独显。
          print(">>> 正在注释 ROCm 复制步骤...")
          lines = content.splitlines()
          final_lines = []
          for line in lines:
              if "COPY --from=rocm" in line:
                  final_lines.append(f"# {line}")
              elif "FROM ubuntu:24.04 AS default" in line:
                  final_lines.append(line)
                  final_lines.append("ENV OLLAMA_VULKAN=1")
              else:
                  final_lines.append(line)
          
          content = "\n".join(final_lines)

          # 写入文件
          with open("Dockerfile", "w") as f:
              f.write(content)
              
          print(">>> Dockerfile 修复完成！新的前 20 行如下：")
          print(content[:800])

      # 4. 登录 GitHub 镜像库
      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # 5. 设置 Docker 环境
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 6. 用户名转小写
      - name: Lowercase Username
        run: |
          echo "OWNER_LC=${USERNAME,,}" >> ${GITHUB_ENV}

      # 7. 编译并推送
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile
          push: true
          tags: ghcr.io/${{ env.OWNER_LC }}/ollama:latest
          platforms: linux/amd64
          no-cache: false
