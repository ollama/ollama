name: Ollama Official + Vulkan

on:
  schedule:
    - cron: '0 22 * * *'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Maximize Disk Space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo docker image prune --all --force

      - name: Checkout Ollama
        uses: actions/checkout@v4
        with:
          repository: ollama/ollama
          ref: main

      - name: Create Dockerfile
        run: |
          cat > Dockerfile << 'EOF'
          # è½»é‡çº§ Vulkan ç¼–è¯‘é˜¶æ®µ
          FROM ubuntu:24.04 AS vulkan-builder
          
          RUN apt-get update && \
              apt-get install -y git build-essential curl ccache wget gnupg && \
              wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | tee /etc/apt/trusted.gpg.d/lunarg.asc && \
              wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list https://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list && \
              apt-get update && apt-get install -y vulkan-sdk && \
              curl -fsSL "https://github.com/Kitware/CMake/releases/download/v3.28.3/cmake-3.28.3-linux-x86_64.tar.gz" | \
                tar xz -C /usr/local --strip-components=1 && \
              rm -rf /var/lib/apt/lists/*
          
          WORKDIR /build
          COPY CMakeLists.txt CMakePresets.json ./
          COPY ml/backend/ggml/ggml ml/backend/ggml/ggml
          
          # å•çº¿ç¨‹ç¼–è¯‘é¿å…è¶…æ—¶å’Œå†…å­˜æº¢å‡º
          RUN cmake --preset Vulkan -DOLLAMA_RUNNER_DIR="vulkan" && \
              cmake --build --preset Vulkan --parallel 1 && \
              cmake --install build --component Vulkan --strip
          
          # æœ€ç»ˆé•œåƒ
          FROM ollama/ollama:latest
          
          RUN apt-get update && \
              apt-get install -y wget gnupg && \
              wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | tee /etc/apt/trusted.gpg.d/lunarg.asc && \
              wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list https://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list && \
              apt-get update && apt-get install -y libvulkan1 vulkan-tools && \
              rm -rf /var/lib/apt/lists/*
          
          COPY --from=vulkan-builder /build/dist/lib/ollama/vulkan /usr/lib/ollama/vulkan
          EOF

      - name: Set up Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Lowercase Username
        run: |
          echo "OWNER_LC=${GITHUB_REPOSITORY_OWNER,,}" >> $GITHUB_ENV

      - name: Build and Push
        uses: docker/build-push-action@v5
        timeout-minutes: 180
        with:
          context: .
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Create Summary
        if: success()
        run: |
          echo "## ðŸŽ‰ æž„å»ºæˆåŠŸ" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ é•œåƒä¿¡æ¯" >> $GITHUB_STEP_SUMMARY
          echo "- **é•œåƒ:** \`${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest\`" >> $GITHUB_STEP_SUMMARY
          echo "- **åŸºç¡€:** ollama/ollama:latest (å« CUDA 11/12/13)" >> $GITHUB_STEP_SUMMARY
          echo "- **æ–°å¢ž:** Vulkan æ”¯æŒ" >> $GITHUB_STEP_SUMMARY
          echo "- **å¤§å°:** ~3.5GB" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ ä½¿ç”¨æ–¹æ³•" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### æ‹‰å–é•œåƒ" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### NVIDIA GPU (CUDA - è‡ªåŠ¨)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d --gpus all \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### AMD æ ¸æ˜¾ (Vulkan)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d \\" >> $GITHUB_STEP_SUMMARY
          echo "  --device=/dev/dri --device=/dev/kfd \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  -e OLLAMA_VULKAN=1 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Intel æ ¸æ˜¾ (Vulkan)" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker run -d \\" >> $GITHUB_STEP_SUMMARY
          echo "  --device=/dev/dri \\" >> $GITHUB_STEP_SUMMARY
          echo "  -v ollama:/root/.ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  -p 11434:11434 \\" >> $GITHUB_STEP_SUMMARY
          echo "  -e OLLAMA_VULKAN=1 \\" >> $GITHUB_STEP_SUMMARY
          echo "  --name ollama \\" >> $GITHUB_STEP_SUMMARY
          echo "  ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/ollama:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ” éªŒè¯" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "# æŸ¥çœ‹ Vulkan åº“" >> $GITHUB_STEP_SUMMARY
          echo "docker exec ollama ls -lh /usr/lib/ollama/vulkan/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# æŸ¥çœ‹ Vulkan è®¾å¤‡" >> $GITHUB_STEP_SUMMARY
          echo "docker exec ollama vulkaninfo --summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# æµ‹è¯•è¿è¡Œ" >> $GITHUB_STEP_SUMMARY
          echo "docker exec -it ollama ollama run llama3.2:1b" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ’¡ æç¤º" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… è‡ªåŠ¨æ”¯æŒ NVIDIA GPU (CUDA 11/12/13)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… æ”¯æŒ AMD/Intel GPU (éœ€è®¾ç½® OLLAMA_VULKAN=1)" >> $GITHUB_STEP_SUMMARY
          echo "- âš ï¸ å•çº¿ç¨‹ç¼–è¯‘ Vulkanï¼Œæž„å»ºæ—¶é—´çº¦ 2-3 å°æ—¶" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Œ é€‰æ‹©ç‰¹å®š GPU: \`GGML_VK_VISIBLE_DEVICES=0\`" >> $GITHUB_STEP_SUMMARY
