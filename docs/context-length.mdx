---
title: Context length
---

Context length is the maximum number of tokens that the model has access to in memory.  

<Note>
  The default context length in Ollama is 4096 tokens.
</Note>

Tasks which require large context like web search, agents, and coding tools should be set to at least 64000 tokens.

## Setting context length

Setting a larger context length will increase the amount of memory required to run a model. Ensure you have enough VRAM available to increase the context length.

Cloud models are set to their maximum context length by default.

### App

Change the slider in the Ollama app under settings to your desired context length.
![Context length in Ollama app](./images/ollama-settings.png)

### CLI

#### Environment Variables

You can configure the context length using the `OLLAMA_CONTEXT_LENGTH` environment variable. This variable will set this as the context length for all models you run.

Look at [FAQ](https://docs.ollama.com/faq#how-do-i-configure-ollama-server) to see how to add an environment variable. 

#### Chat Mode
The context length can also be adjusted while running a model interactively (via `ollama run`), this will set a specific context length per model.

Start the model:
```
ollama run <model>
```

Inside the interactive prompt, set the context length:
```
/set parameter num_ctx 65536
```

This change applies only to the current session.

#### Saving the configuration permanently
To persist the updated context length, save the model configuration under a new name:

```
/save <model>_64k
```

For example, if your model is named `gemma3:12b`, you could save it as:

```
/save gemma3:12b_64k
```

From then on, run the saved model:

```
ollama run gemma3:12b_64k
```

### Check allocated context length and model offloading
For best performance, use the maximum context length for a model, and avoid offloading the model to CPU. Verify the split under `PROCESSOR` using `ollama ps`.
```
ollama ps
```
```
NAME             ID              SIZE      PROCESSOR    CONTEXT    UNTIL
gemma3:latest    a2af6cc3eb7f    6.6 GB    100% GPU     65536      2 minutes from now
```
