From e559ff21a1f20a8d2104bcb625a34d29f24b9026 Mon Sep 17 00:00:00 2001
From: Agustin Alexander <agustin.alexander@dominodatalab.com>
Date: Thu, 7 Aug 2025 19:52:24 -0300
Subject: [PATCH 1/3] feat(vulkan): add Vulkan ggml backend packaging;
 discovery and env wiring; no-mmap policy; Docker runtime deps

---
 CMakeLists.txt             |  12 ++
 Dockerfile                 |  10 +-
 discover/gpu.go            | 119 ++++++++++++++-
 discover/gpu_info.h        |   1 +
 discover/gpu_info_vulkan.c | 288 +++++++++++++++++++++++++++++++++++++
 discover/gpu_info_vulkan.h |  69 +++++++++
 discover/path.go           |   4 +-
 discover/types.go          |   8 +-
 discover/vulkan_common.go  |  21 +++
 envconfig/config.go        |   2 +
 llm/server.go              |  26 ++--
 11 files changed, 537 insertions(+), 23 deletions(-)
 create mode 100644 discover/gpu_info_vulkan.c
 create mode 100644 discover/gpu_info_vulkan.h
 create mode 100644 discover/vulkan_common.go

diff --git a/CMakeLists.txt b/CMakeLists.txt
index b3b5438a..f9bef39b 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -62,6 +62,18 @@ if(NOT CPU_VARIANTS)
     set(CPU_VARIANTS "ggml-cpu")
 endif()
 
+find_package(Vulkan)
+if(Vulkan_FOUND)
+    add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/ml/backend/ggml/ggml/src/ggml-vulkan)
+    set(OLLAMA_VULKAN_INSTALL_DIR ${OLLAMA_INSTALL_DIR}/vulkan)
+    install(TARGETS ggml-vulkan
+        RUNTIME_DEPENDENCIES
+            PRE_INCLUDE_REGEXES vulkan
+            PRE_EXCLUDE_REGEXES ".*"
+        RUNTIME DESTINATION ${OLLAMA_VULKAN_INSTALL_DIR} COMPONENT Vulkan
+        LIBRARY DESTINATION ${OLLAMA_VULKAN_INSTALL_DIR} COMPONENT Vulkan
+    )
+endif()
 install(TARGETS ggml-base ${CPU_VARIANTS}
     RUNTIME_DEPENDENCIES
         PRE_EXCLUDE_REGEXES ".*"
diff --git a/Dockerfile b/Dockerfile
index 776fabeb..0ee6d2cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -6,6 +6,7 @@ ARG ROCMVERSION=6.3.3
 ARG JETPACK5VERSION=r35.4.1
 ARG JETPACK6VERSION=r36.4.0
 ARG CMAKEVERSION=3.31.2
+ARG VULKANVERSION=1.4.304.1
 
 # We require gcc v10 minimum.  v10.3 has regressions, so the rockylinux 8.5 AppStream has the latest compatible version
 FROM --platform=linux/amd64 rocm/dev-almalinux-8:${ROCMVERSION}-complete AS base-amd64
@@ -30,6 +31,12 @@ RUN curl -fsSL https://github.com/Kitware/CMake/releases/download/v${CMAKEVERSIO
 COPY CMakeLists.txt CMakePresets.json .
 COPY ml/backend/ggml/ggml ml/backend/ggml/ggml
 ENV LDFLAGS=-s
+FROM base AS vulkan
+RUN --mount=type=cache,target=/root/.ccache \
+    cmake --preset 'Vulkan' \
+        && cmake --build --parallel --preset 'Vulkan' \
+        && cmake --install build --component Vulkan --strip --parallel 8
+
 
 FROM base AS cpu
 RUN dnf install -y gcc-toolset-11-gcc gcc-toolset-11-gcc-c++
@@ -91,6 +98,7 @@ RUN --mount=type=cache,target=/root/.cache/go-build \
 
 FROM --platform=linux/amd64 scratch AS amd64
 COPY --from=cuda-12 dist/lib/ollama /lib/ollama
+COPY --from=vulkan  dist/lib/ollama/vulkan  /lib/ollama/vulkan
 
 FROM --platform=linux/arm64 scratch AS arm64
 COPY --from=cuda-12 dist/lib/ollama /lib/ollama/cuda_sbsa
@@ -106,7 +114,7 @@ COPY --from=build /bin/ollama /bin/ollama
 
 FROM ubuntu:24.04
 RUN apt-get update \
-    && apt-get install -y ca-certificates \
+    && apt-get install -y ca-certificates libcap2 libvulkan1 \
     && apt-get clean \
     && rm -rf /var/lib/apt/lists/*
 COPY --from=archive /bin /usr/bin
diff --git a/discover/gpu.go b/discover/gpu.go
index 15bad446..87296a9f 100644
--- a/discover/gpu.go
+++ b/discover/gpu.go
@@ -37,6 +37,11 @@ type oneapiHandles struct {
 	deviceCount int
 }
 
+type vulkanHandles struct {
+    vulkan      *C.vk_handle_t
+    deviceCount int
+}
+
 const (
 	cudaMinimumMemory = 457 * format.MebiByte
 	rocmMinimumMemory = 457 * format.MebiByte
@@ -48,9 +53,17 @@ var (
 	bootstrapped  bool
 	cpus          []CPUInfo
 	cudaGPUs      []CudaGPUInfo
+    vulkanGPUs    []VulkanGPUInfo
 	nvcudaLibPath string
 	cudartLibPath string
-	oneapiLibPath string
+    oneapiLibPath string
+    // vulkan paths for runtime and libcap
+    // filled by LoadVulkanMgmt on first success
+    // used to short-circuit subsequent refreshes
+    libcapLibPath string
+    vulkanLibPath string
+    vulkanLibPath string
+    libcapLibPath string
 	nvmlLibPath   string
 	rocmGPUs      []RocmGPUInfo
 	oneapiGPUs    []OneapiGPUInfo
@@ -247,8 +260,9 @@ func GetGPUInfo() GpuInfoList {
 			},
 		}
 
-		// Load ALL libraries
+        // Load ALL libraries
 		cHandles = initCudaHandles()
+        vHandles := initVulkanHandles()
 
 		// NVIDIA
 		for i := range cHandles.deviceCount {
@@ -368,12 +382,42 @@ func GetGPUInfo() GpuInfoList {
 			}
 		}
 
-		rocmGPUs, err = AMDGetGPUInfo()
+        // Vulkan
+        for i := range vHandles.deviceCount {
+            if vHandles.vulkan != nil {
+                gpuInfo := VulkanGPUInfo{
+                    GpuInfo: GpuInfo{
+                        Library: "vulkan",
+                    },
+                    index: i,
+                }
+
+                C.vk_check_vram(*vHandles.vulkan, C.int(i), &memInfo)
+                if memInfo.err != nil {
+                    slog.Info("error looking up vulkan GPU memory", "error", C.GoString(memInfo.err))
+                    C.free(unsafe.Pointer(memInfo.err))
+                    continue
+                }
+
+                gpuInfo.TotalMemory = uint64(memInfo.total)
+                gpuInfo.FreeMemory = uint64(memInfo.free)
+                gpuInfo.ID = C.GoString(&memInfo.gpu_id[0])
+                gpuInfo.Compute = fmt.Sprintf("%d.%d", memInfo.major, memInfo.minor)
+                gpuInfo.MinimumMemory = 0
+                gpuInfo.Name = C.GoString(&memInfo.gpu_name[0])
+                gpuInfo.DriverMajor = int(memInfo.major)
+                gpuInfo.DriverMinor = int(memInfo.minor)
+
+                vulkanGPUs = append(vulkanGPUs, gpuInfo)
+            }
+        }
+
+        rocmGPUs, err = AMDGetGPUInfo()
 		if err != nil {
 			bootstrapErrors = append(bootstrapErrors, err)
 		}
 		bootstrapped = true
-		if len(cudaGPUs) == 0 && len(rocmGPUs) == 0 && len(oneapiGPUs) == 0 {
+        if len(cudaGPUs) == 0 && len(rocmGPUs) == 0 && len(oneapiGPUs) == 0 && len(vulkanGPUs) == 0 {
 			slog.Info("no compatible GPUs were discovered")
 		}
 
@@ -457,7 +501,7 @@ func GetGPUInfo() GpuInfoList {
 			cudaGPUs[i].FreeMemory = uint64(memInfo.free)
 		}
 
-		if oHandles == nil && len(oneapiGPUs) > 0 {
+        if oHandles == nil && len(oneapiGPUs) > 0 {
 			oHandles = initOneAPIHandles()
 		}
 		for i, gpu := range oneapiGPUs {
@@ -473,7 +517,23 @@ func GetGPUInfo() GpuInfoList {
 			oneapiGPUs[i].FreeMemory = uint64(memInfo.free)
 		}
 
-		err = RocmGPUInfoList(rocmGPUs).RefreshFreeMemory()
+        // Vulkan refresh
+        if len(vulkanGPUs) > 0 {
+            vHandles = initVulkanHandles()
+            for i := range vulkanGPUs {
+                if vHandles.vulkan == nil {
+                    slog.Warn("nil vulkan handle with device count", "count", vHandles.deviceCount)
+                    break
+                }
+                C.vk_check_vram(*vHandles.vulkan, C.int(vulkanGPUs[i].index), &memInfo)
+                // leave 5% headroom like oneAPI workaround
+                var totalFreeMem float64 = float64(memInfo.free) * 0.95
+                memInfo.free = C.uint64_t(totalFreeMem)
+                vulkanGPUs[i].FreeMemory = uint64(memInfo.free)
+            }
+        }
+
+        err = RocmGPUInfoList(rocmGPUs).RefreshFreeMemory()
 		if err != nil {
 			slog.Debug("problem refreshing ROCm free memory", "error", err)
 		}
@@ -489,6 +549,9 @@ func GetGPUInfo() GpuInfoList {
 	for _, gpu := range oneapiGPUs {
 		resp = append(resp, gpu.GpuInfo)
 	}
+    for _, gpu := range vulkanGPUs {
+        resp = append(resp, gpu.GpuInfo)
+    }
 	if len(resp) == 0 {
 		resp = append(resp, cpus[0].GpuInfo)
 	}
@@ -669,8 +732,48 @@ func loadOneapiMgmt(oneapiLibPaths []string) (int, *C.oneapi_handle_t, string, e
 	return 0, nil, "", err
 }
 
+func LoadVulkanMgmt(vulkanLibPaths []string, capLibPaths []string) (int, *C.vk_handle_t, string, string) {
+    var resp C.vk_init_resp_t
+    resp.ch.verbose = getVerboseState()
+    for _, vkLibPath := range vulkanLibPaths {
+        for _, capLibPath := range capLibPaths {
+            vkLib := C.CString(vkLibPath)
+            capLib := C.CString(capLibPath)
+            defer C.free(unsafe.Pointer(vkLib))
+            defer C.free(unsafe.Pointer(capLib))
+
+            C.vk_init(vkLib, capLib, &resp)
+            if resp.err != nil {
+                slog.Debug("Unable to load vulkan", "library", vkLibPath, capLibPath, "error", C.GoString(resp.err))
+                C.free(unsafe.Pointer(resp.err))
+            } else {
+                return int(resp.num_devices), &resp.ch, vkLibPath, capLibPath
+            }
+        }
+    }
+    return 0, nil, "", ""
+}
+
+func initVulkanHandles() *vulkanHandles {
+    vHandles := &vulkanHandles{}
+
+    if vulkanLibPath != "" && libcapLibPath != "" {
+        vHandles.deviceCount, vHandles.vulkan, _, _ = LoadVulkanMgmt([]string{vulkanLibPath}, []string{libcapLibPath})
+        return vHandles
+    }
+
+    vulkanPaths := FindGPULibs(VulkanMgmtName, VulkanGlobs)
+    libcapPaths := FindLibCapLibs()
+
+    if len(vulkanPaths) > 0 && len(libcapPaths) > 0 {
+        vHandles.deviceCount, vHandles.vulkan, vulkanLibPath, libcapLibPath = LoadVulkanMgmt(vulkanPaths, libcapPaths)
+    }
+
+    return vHandles
+}
+
 func getVerboseState() C.uint16_t {
-	if envconfig.LogLevel() < slog.LevelInfo {
+    if envconfig.LogLevel() < slog.LevelInfo {
 		return C.uint16_t(1)
 	}
 	return C.uint16_t(0)
@@ -691,6 +794,8 @@ func (l GpuInfoList) GetVisibleDevicesEnv() (string, string) {
 		return rocmGetVisibleDevicesEnv(l)
 	case "oneapi":
 		return oneapiGetVisibleDevicesEnv(l)
+    case "vulkan":
+        return vkGetVisibleDevicesEnv(l)
 	default:
 		slog.Debug("no filter required for library " + l[0].Library)
 		return "", ""
diff --git a/discover/gpu_info.h b/discover/gpu_info.h
index ee7ff4c3..7356a138 100644
--- a/discover/gpu_info.h
+++ b/discover/gpu_info.h
@@ -67,6 +67,7 @@ void cpu_check_ram(mem_info_t *resp);
 #include "gpu_info_nvcuda.h"
 #include "gpu_info_nvml.h"
 #include "gpu_info_oneapi.h"
+#include "gpu_info_vulkan.h"
 
 #endif  // __GPU_INFO_H__
 #endif  // __APPLE__
diff --git a/discover/gpu_info_vulkan.c b/discover/gpu_info_vulkan.c
new file mode 100644
index 00000000..08422e76
--- /dev/null
+++ b/discover/gpu_info_vulkan.c
@@ -0,0 +1,288 @@
+#include "gpu_info_vulkan.h"
+
+#include <string.h>
+
+int check_perfmon(vk_handle_t* rh) {
+#ifdef __linux__
+  cap_t caps;
+  const cap_value_t cap_list[1] = {CAP_PERFMON};
+
+  caps = (*rh->cap_get_proc)();
+  if (caps == NULL)
+    return -1;
+
+  if ((*rh->cap_set_flag)(caps, CAP_EFFECTIVE, 1, cap_list, CAP_SET) == -1)
+    return -1;
+
+  if ((*rh->cap_set_proc)(caps) == -1)
+    return -1;
+
+  if ((*rh->cap_free)(caps) == -1)
+    return -1;
+#endif
+
+  return 0;
+}
+
+int is_extension_supported(vk_handle_t* rh, VkPhysicalDevice device, char* extension) {
+  VkPhysicalDeviceProperties properties;
+  (*rh->vkGetPhysicalDeviceProperties)(device, &properties);
+
+  uint32_t extensionCount;
+  (*rh->vkEnumerateDeviceExtensionProperties)(device, NULL, &extensionCount, NULL);
+
+  if (extensionCount == 0) {
+    return 0;
+  }
+
+  VkExtensionProperties* extensions = malloc(extensionCount * sizeof(VkExtensionProperties));
+  if (extensions == NULL) {
+    return 0;
+  }
+
+  (*rh->vkEnumerateDeviceExtensionProperties)(device, NULL, &extensionCount, extensions);
+
+  for (int j = 0; j < extensionCount; j++) {
+    if (strcmp(extensions[j].extensionName, extension) == 0) {
+      free(extensions);
+      return 1;
+    }
+  }
+
+  free(extensions);
+  return 0;
+}
+
+void vk_init(char* vk_lib_path, char* cap_lib_path, vk_init_resp_t *resp) {
+  const int buflen = 256;
+  char buf[buflen + 1];
+  int i;
+
+  struct lookup {
+    int is_cap;
+    char *s;
+    void **p;
+  } l[] = {
+#ifdef __linux__
+      {1, "cap_get_proc", (void *)&resp->ch.cap_get_proc},
+      {1, "cap_get_bound", (void *)&resp->ch.cap_get_bound},
+      {1, "cap_set_flag", (void *)&resp->ch.cap_set_flag},
+      {1, "cap_set_proc", (void *)&resp->ch.cap_set_proc},
+      {1, "cap_free", (void *)&resp->ch.cap_free},
+#endif
+      {0, "vkGetPhysicalDeviceProperties", (void *)&resp->ch.vkGetPhysicalDeviceProperties},
+      {0, "vkEnumerateDeviceExtensionProperties", (void *)&resp->ch.vkEnumerateDeviceExtensionProperties},
+      {0, "vkCreateInstance", (void *)&resp->ch.vkCreateInstance},
+      {0, "vkEnumeratePhysicalDevices", (void *)&resp->ch.vkEnumeratePhysicalDevices},
+      {0, "vkGetPhysicalDeviceMemoryProperties2", (void *)&resp->ch.vkGetPhysicalDeviceMemoryProperties2},
+      {0, "vkDestroyInstance", (void *)&resp->ch.vkDestroyInstance},
+      {0, NULL, NULL},
+  };
+
+  resp->ch.vk_handle = LOAD_LIBRARY(vk_lib_path, RTLD_LAZY);
+  if (!resp->ch.vk_handle) {
+    char *msg = LOAD_ERR();
+    LOG(resp->ch.verbose, "library %s load err: %s\n", vk_lib_path, msg);
+    snprintf(buf, buflen,
+            "Unable to load %s library to query for Vulkan GPUs: %s",
+            vk_lib_path, msg);
+    free(msg);
+    resp->err = strdup(buf);
+    return;
+  }
+
+#ifdef __linux__
+  resp->ch.cap_handle = LOAD_LIBRARY(cap_lib_path, RTLD_LAZY);
+  if (!resp->ch.cap_handle) {
+    char *msg = LOAD_ERR();
+    LOG(resp->ch.verbose, "library %s load err: %s\n", cap_lib_path, msg);
+    snprintf(buf, buflen,
+            "Unable to load %s library to query for Vulkan GPUs: %s",
+            cap_lib_path, msg);
+    free(msg);
+    resp->err = strdup(buf);
+    return;
+  }
+#endif
+
+  for (i = 0; l[i].s != NULL; i++) {
+    if (l[i].is_cap)
+#ifdef __linux__
+      *l[i].p = LOAD_SYMBOL(resp->ch.cap_handle, l[i].s);
+#else
+      continue;
+#endif
+    else
+      *l[i].p = LOAD_SYMBOL(resp->ch.vk_handle, l[i].s);
+    if (!*l[i].p) {
+      char *msg = LOAD_ERR();
+      LOG(resp->ch.verbose, "dlerr: %s\n", msg);
+      if (l[i].is_cap) {
+        UNLOAD_LIBRARY(resp->ch.cap_handle);
+        resp->ch.cap_handle = NULL;
+      } else {
+        UNLOAD_LIBRARY(resp->ch.vk_handle);
+        resp->ch.vk_handle = NULL;
+      }
+      snprintf(buf, buflen, "symbol lookup for %s failed: %s", l[i].s,
+              msg);
+      free(msg);
+      resp->err = strdup(buf);
+      return;
+    }
+  }
+
+  if (check_perfmon(&resp->ch) != 0) {
+    resp->err = strdup("performance monitoring is not allowed. Please enable CAP_PERFMON or run as root to use Vulkan.");
+    LOG(resp->ch.verbose, "vulkan: %s", resp->err);
+    return;
+  }
+
+  VkInstance instance;
+
+  VkApplicationInfo appInfo = {};
+  appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
+  appInfo.pNext = NULL;
+  appInfo.pApplicationName = "Ollama";
+  appInfo.applicationVersion = VK_MAKE_VERSION(1, 0, 0);
+  appInfo.pEngineName = "No Engine";
+  appInfo.engineVersion = VK_MAKE_VERSION(1, 0, 0);
+  appInfo.apiVersion = VK_API_VERSION_1_2;
+
+  VkInstanceCreateInfo createInfo = {};
+  createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
+  createInfo.pNext = NULL;
+  createInfo.flags = 0;
+  createInfo.enabledExtensionCount = 1;
+  const char* extensions[] = { VK_KHR_GET_PHYSICAL_DEVICE_PROPERTIES_2_EXTENSION_NAME };
+  createInfo.ppEnabledExtensionNames = extensions;
+  createInfo.pApplicationInfo = &appInfo;
+
+  VkResult result = (*resp->ch.vkCreateInstance)(&createInfo, NULL, &instance);
+  if (result != VK_SUCCESS) {
+    resp->err = strdup("failed to create instance");
+    return;
+  }
+
+  uint32_t deviceCount;
+  result = (*resp->ch.vkEnumeratePhysicalDevices)(instance, &deviceCount, NULL);
+  if (result != VK_SUCCESS) {
+    resp->err = strdup("failed to enumerate physical devices");
+    return;
+  }
+
+  resp->err = NULL;
+  resp->ch.vk = instance;
+  resp->ch.num_devices = deviceCount;
+  resp->num_devices = deviceCount;
+}
+
+int vk_check_flash_attention(vk_handle_t rh, int i) {
+  VkInstance instance = rh.vk;
+  uint32_t deviceCount = rh.num_devices;
+
+  VkPhysicalDevice* devices = malloc(deviceCount * sizeof(VkPhysicalDevice));
+  if (devices == NULL) {
+    return 0;
+  }
+
+  VkResult result = (*rh.vkEnumeratePhysicalDevices)(instance, &deviceCount, devices);
+  if (result != VK_SUCCESS) {
+    free(devices);
+    return 0;
+  }
+
+  VkPhysicalDeviceProperties properties;
+  (*rh.vkGetPhysicalDeviceProperties)(devices[i], &properties);
+
+  int supports_nv_coopmat2 = is_extension_supported(&rh, devices[i], VK_NV_COOPERATIVE_MATRIX_2_EXTENSION_NAME);
+  if (!supports_nv_coopmat2) {
+    free(devices);
+    return 1;
+  }
+
+  free(devices);
+  return 0;
+}
+
+void vk_check_vram(vk_handle_t rh, int i, mem_info_t *resp) {
+  VkInstance instance = rh.vk;
+  uint32_t deviceCount = rh.num_devices;
+
+  VkPhysicalDevice* devices = malloc(deviceCount * sizeof(VkPhysicalDevice));
+  if (devices == NULL) {
+    resp->err = strdup("memory allocation failed for devices array");
+    return;
+  }
+
+  VkResult result = (*rh.vkEnumeratePhysicalDevices)(instance, &deviceCount, devices);
+  if (result != VK_SUCCESS) {
+    free(devices);
+    resp->err = strdup("failed to enumerate physical devices");
+    return;
+  }
+
+  VkPhysicalDeviceProperties properties;
+  (*rh->vkGetPhysicalDeviceProperties)(devices[i], &properties);
+
+  int supports_budget = is_extension_supported(&rh, devices[i], VK_EXT_MEMORY_BUDGET_EXTENSION_NAME);
+  if (!supports_budget) {
+    free(devices);
+    resp->err = strdup("device does not support memory budget");
+    return;
+  }
+
+  if (properties.deviceType == VK_PHYSICAL_DEVICE_TYPE_CPU) {
+    free(devices);
+    resp->err = strdup("device is a CPU");
+    return;
+  }
+
+  VkPhysicalDeviceMemoryBudgetPropertiesEXT physical_device_memory_budget_properties;
+  physical_device_memory_budget_properties.sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_BUDGET_PROPERTIES_EXT;
+  physical_device_memory_budget_properties.pNext = NULL;
+
+  VkPhysicalDeviceMemoryProperties2 device_memory_properties;
+  device_memory_properties.sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2;
+  device_memory_properties.pNext = &physical_device_memory_budget_properties;
+
+  (*rh.vkGetPhysicalDeviceMemoryProperties2)(devices[i], &device_memory_properties);
+
+  VkDeviceSize device_memory_total_size  = 0;
+  VkDeviceSize device_memory_heap_budget = 0;
+
+  for (uint32_t j = 0; j < device_memory_properties.memoryProperties.memoryHeapCount; j++) {
+    VkMemoryHeap heap = device_memory_properties.memoryProperties.memoryHeaps[j];
+    if (heap.flags & VK_MEMORY_HEAP_DEVICE_LOCAL_BIT) {
+      device_memory_total_size  += heap.size;
+      device_memory_heap_budget += physical_device_memory_budget_properties.heapBudget[j];
+    }
+  }
+
+  free(devices);
+
+  resp->err = NULL;
+  snprintf(&resp->gpu_id[0], GPU_ID_LEN, "%d", i);
+  resp->gpu_name[GPU_NAME_LEN - 1] = '\0';
+  strncpy(&resp->gpu_name[0], properties.deviceName, GPU_NAME_LEN - 1);
+  resp->total = (uint64_t) device_memory_total_size;
+  resp->free = (uint64_t) device_memory_heap_budget;
+  resp->major = VK_API_VERSION_MAJOR(properties.apiVersion);
+  resp->minor = VK_API_VERSION_MINOR(properties.apiVersion);
+  resp->patch = VK_API_VERSION_PATCH(properties.apiVersion);
+}
+
+void vk_release(vk_handle_t rh) {
+  LOG(rh.verbose, "releasing vulkan library\n");
+  (*rh.vkDestroyInstance)(rh.vk, NULL);
+  UNLOAD_LIBRARY(rh.vk_handle);
+  rh.vk_handle = NULL;
+
+#ifdef __linux__
+  LOG(rh.verbose, "releasing libcap library\n");
+  UNLOAD_LIBRARY(rh.cap_handle);
+  rh.cap_handle = NULL;
+#endif
+}
+
+
diff --git a/discover/gpu_info_vulkan.h b/discover/gpu_info_vulkan.h
new file mode 100644
index 00000000..e7669c7c
--- /dev/null
+++ b/discover/gpu_info_vulkan.h
@@ -0,0 +1,69 @@
+#ifndef __APPLE__
+#ifndef __GPU_INFO_VULKAN_H__
+#define __GPU_INFO_VULKAN_H__
+
+#include "gpu_info.h"
+
+#ifdef __linux__
+#include <sys/capability.h>
+#endif
+
+#include <vulkan/vulkan.h>
+
+typedef struct {
+  void* vk_handle;
+  void* cap_handle;
+  uint16_t verbose;
+
+  VkInstance vk;
+  int num_devices;
+
+#ifdef __linux__
+  cap_t (*cap_get_proc)(void);
+
+  int (*cap_get_bound)(cap_value_t);
+  int (*cap_set_flag)(cap_t, cap_flag_t, int, const cap_value_t *, cap_flag_value_t);
+  int (*cap_set_proc)(cap_t);
+  int (*cap_free)(cap_t);
+#endif
+
+  void (*vkGetPhysicalDeviceProperties)(
+    VkPhysicalDevice                            physicalDevice,
+    VkPhysicalDeviceProperties*                 pProperties);
+  VkResult (*vkEnumerateDeviceExtensionProperties)(
+      VkPhysicalDevice                            physicalDevice,
+      const char*                                 pLayerName,
+      uint32_t*                                   pPropertyCount,
+      VkExtensionProperties*                      pProperties);
+  VkResult (*vkCreateInstance)(
+      const VkInstanceCreateInfo*                 pCreateInfo,
+      const VkAllocationCallbacks*                pAllocator,
+      VkInstance*                                 pInstance);
+  VkResult (*vkEnumeratePhysicalDevices)(
+      VkInstance                                  instance,
+      uint32_t*                                   pPhysicalDeviceCount,
+      VkPhysicalDevice*                           pPhysicalDevices);
+  void (*vkGetPhysicalDeviceMemoryProperties2)(
+      VkPhysicalDevice                            physicalDevice,
+      VkPhysicalDeviceMemoryProperties2*          pMemoryProperties);
+  void (*vkDestroyInstance)(
+      VkInstance                                  instance,
+      const VkAllocationCallbacks*                pAllocator);
+} vk_handle_t;
+
+typedef struct vk_init_resp
+{
+  char *err; // If err is non-null handle is invalid
+  int num_devices;
+  vk_handle_t ch;
+} vk_init_resp_t;
+
+void vk_init(char* vk_lib_path, char* cap_lib_path, vk_init_resp_t *resp);
+void vk_check_vram(vk_handle_t rh, int i, mem_info_t *resp);
+int vk_check_flash_attention(vk_handle_t rh, int i);
+void vk_release(vk_handle_t rh);
+
+#endif
+#endif
+
+
diff --git a/discover/path.go b/discover/path.go
index 68e63009..9af89b66 100644
--- a/discover/path.go
+++ b/discover/path.go
@@ -11,8 +11,8 @@ import (
 // in distribution builds it's 'lib/ollama' on Windows
 // '../lib/ollama' on Linux and the executable's directory on macOS
 // note: distribution builds, additional GPU-specific libraries are
-// found in subdirectories of the returned path, such as
-// 'cuda_v12', 'rocm', etc.
+    // found in subdirectories of the returned path, such as
+    // 'cuda_v12', 'rocm', 'vulkan', etc.
 var LibOllamaPath string = func() string {
 	exe, err := os.Executable()
 	if err != nil {
diff --git a/discover/types.go b/discover/types.go
index c5212d94..bb0e56b3 100644
--- a/discover/types.go
+++ b/discover/types.go
@@ -92,6 +92,11 @@ type OneapiGPUInfo struct {
 }
 type OneapiGPUInfoList []OneapiGPUInfo
 
+type VulkanGPUInfo struct {
+    GpuInfo
+    index int //nolint:unused,nolintlint
+}
+
 type GpuInfoList []GpuInfo
 
 type UnsupportedGPUInfo struct {
@@ -173,7 +178,8 @@ func (l GpuInfoList) FlashAttentionSupported() bool {
 	for _, gpu := range l {
 		supportsFA := gpu.Library == "metal" ||
 			(gpu.Library == "cuda" && gpu.DriverMajor >= 7) ||
-			gpu.Library == "rocm"
+            gpu.Library == "rocm" ||
+            gpu.Library == "vulkan"
 
 		if !supportsFA {
 			return false
diff --git a/discover/vulkan_common.go b/discover/vulkan_common.go
new file mode 100644
index 00000000..2f238b49
--- /dev/null
+++ b/discover/vulkan_common.go
@@ -0,0 +1,21 @@
+package discover
+
+import (
+    "log/slog"
+    "strings"
+)
+
+func vkGetVisibleDevicesEnv(gpuInfo []GpuInfo) (string, string) {
+    ids := []string{}
+    for _, info := range gpuInfo {
+        if info.Library != "vulkan" {
+            // TODO shouldn't happen if things are wired correctly...
+            slog.Debug("vkGetVisibleDevicesEnv skipping over non-vulkan device", "library", info.Library)
+            continue
+        }
+        ids = append(ids, info.ID)
+    }
+    return "GGML_VK_VISIBLE_DEVICES", strings.Join(ids, ",")
+}
+
+
diff --git a/envconfig/config.go b/envconfig/config.go
index 7fc01887..4b719a77 100644
--- a/envconfig/config.go
+++ b/envconfig/config.go
@@ -199,6 +199,7 @@ var (
 	CudaVisibleDevices    = String("CUDA_VISIBLE_DEVICES")
 	HipVisibleDevices     = String("HIP_VISIBLE_DEVICES")
 	RocrVisibleDevices    = String("ROCR_VISIBLE_DEVICES")
+    VkVisibleDevices      = String("GGML_VK_VISIBLE_DEVICES")
 	GpuDeviceOrdinal      = String("GPU_DEVICE_ORDINAL")
 	HsaOverrideGfxVersion = String("HSA_OVERRIDE_GFX_VERSION")
 )
@@ -288,6 +289,7 @@ func AsMap() map[string]EnvVar {
 		ret["CUDA_VISIBLE_DEVICES"] = EnvVar{"CUDA_VISIBLE_DEVICES", CudaVisibleDevices(), "Set which NVIDIA devices are visible"}
 		ret["HIP_VISIBLE_DEVICES"] = EnvVar{"HIP_VISIBLE_DEVICES", HipVisibleDevices(), "Set which AMD devices are visible by numeric ID"}
 		ret["ROCR_VISIBLE_DEVICES"] = EnvVar{"ROCR_VISIBLE_DEVICES", RocrVisibleDevices(), "Set which AMD devices are visible by UUID or numeric ID"}
+        ret["GGML_VK_VISIBLE_DEVICES"] = EnvVar{"GGML_VK_VISIBLE_DEVICES", VkVisibleDevices(), "Set which Vulkan devices are visible by numeric ID"}
 		ret["GPU_DEVICE_ORDINAL"] = EnvVar{"GPU_DEVICE_ORDINAL", GpuDeviceOrdinal(), "Set which AMD devices are visible by numeric ID"}
 		ret["HSA_OVERRIDE_GFX_VERSION"] = EnvVar{"HSA_OVERRIDE_GFX_VERSION", HsaOverrideGfxVersion(), "Override the gfx used for all detected AMD GPUs"}
 		ret["OLLAMA_INTEL_GPU"] = EnvVar{"OLLAMA_INTEL_GPU", IntelGPU(), "Enable experimental Intel GPU detection"}
diff --git a/llm/server.go b/llm/server.go
index 7d921f14..f1d8d8dc 100644
--- a/llm/server.go
+++ b/llm/server.go
@@ -239,13 +239,15 @@ func NewLlamaServer(gpus discover.GpuInfoList, modelPath string, f *ggml.GGML, a
 		}
 	}
 
-	// Windows CUDA should not use mmap for best performance
-	// Linux  with a model larger than free space, mmap leads to thrashing
-	// For CPU loads we want the memory to be allocated, not FS cache
-	if (runtime.GOOS == "windows" && gpus[0].Library == "cuda" && opts.UseMMap == nil) ||
-		(runtime.GOOS == "linux" && systemFreeMemory < estimate.TotalSize && opts.UseMMap == nil) ||
-		(gpus[0].Library == "cpu" && opts.UseMMap == nil) ||
-		(opts.UseMMap != nil && !*opts.UseMMap) {
+    // Windows CUDA should not use mmap for best performance
+    // Vulkan should not use mmap because of double allocation (VRAM + RAM)
+    // Linux  with a model larger than free space, mmap leads to thrashing
+    // For CPU loads we want the memory to be allocated, not FS cache
+    if (runtime.GOOS == "windows" && gpus[0].Library == "cuda" && opts.UseMMap == nil) ||
+        (runtime.GOOS == "linux" && systemFreeMemory < estimate.TotalSize && opts.UseMMap == nil) ||
+        (gpus[0].Library == "vulkan" && opts.UseMMap == nil) ||
+        (gpus[0].Library == "cpu" && opts.UseMMap == nil) ||
+        (opts.UseMMap != nil && !*opts.UseMMap) {
 		params = append(params, "--no-mmap")
 	}
 
@@ -353,14 +355,14 @@ func NewLlamaServer(gpus discover.GpuInfoList, modelPath string, f *ggml.GGML, a
 			pathEnv = "LD_LIBRARY_PATH"
 		}
 
-		// Note: we always put our dependency paths first
-		// since these are the exact version we compiled/linked against
-		libraryPaths := []string{discover.LibOllamaPath}
+        // Note: we always put our dependency paths first
+        // since these are the exact version we compiled/linked against
+        libraryPaths := []string{discover.LibOllamaPath}
 		if libraryPath, ok := os.LookupEnv(pathEnv); ok {
 			libraryPaths = append(libraryPaths, filepath.SplitList(libraryPath)...)
 		}
 
-		ggmlPaths := []string{discover.LibOllamaPath}
+        ggmlPaths := []string{discover.LibOllamaPath}
 		if len(compatible) > 0 {
 			c := compatible[0]
 			if libpath, ok := libs[c]; ok {
@@ -406,7 +408,7 @@ func NewLlamaServer(gpus discover.GpuInfoList, modelPath string, f *ggml.GGML, a
 		for _, gpu := range gpus {
 			envWorkarounds = append(envWorkarounds, gpu.EnvWorkarounds...)
 		}
-		visibleDevicesEnv, visibleDevicesEnvVal := gpus.GetVisibleDevicesEnv()
+        visibleDevicesEnv, visibleDevicesEnvVal := gpus.GetVisibleDevicesEnv()
 		pathEnvVal := strings.Join(libraryPaths, string(filepath.ListSeparator))
 
 		// Update or add the path and visible devices variable with our adjusted version
-- 
2.50.0

